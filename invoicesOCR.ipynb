{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'Converted_Images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pdf_folder = 'PDFS'\n",
    "pdf_files = glob.glob(os.path.join(pdf_folder, '*.pdf'))\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    images = convert_from_path(pdf_file, 500, poppler_path=r'C:\\Program Files\\poppler-23.05.0\\Library\\bin')\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        image_path = os.path.join(output_dir, f'{os.path.splitext(os.path.basename(pdf_file))[0]}_page{i}.jpg')\n",
    "        image.save(image_path)\n",
    "        print(\"Converted:\", image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreProcessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = 'Processed_Images'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Correction\n",
    "def color_correction(image):\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    clahe_l_channel = clahe.apply(l_channel)\n",
    "    corrected_lab_image = cv2.merge((clahe_l_channel, a_channel, b_channel))\n",
    "    corrected_image = cv2.cvtColor(corrected_lab_image, cv2.COLOR_LAB2BGR)\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brightness Adjustment\n",
    "def adjust_brightness(image, value):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    h_channel, s_channel, v_channel = cv2.split(hsv_image)\n",
    "    v_channel = np.clip(v_channel + value, 0, 255)\n",
    "    adjusted_hsv_image = cv2.merge((h_channel, s_channel, v_channel))\n",
    "    adjusted_image = cv2.cvtColor(adjusted_hsv_image, cv2.COLOR_HSV2BGR)\n",
    "    return adjusted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Image Entropy\n",
    "def calculate_entropy(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    hist /= hist.sum()\n",
    "    entropy = -np.sum(hist * np.log2(hist + np.finfo(float).eps))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Image Edge Density\n",
    "def calculate_edge_density(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_image, 50, 150)\n",
    "    edge_density = np.count_nonzero(edges) / (edges.shape[0] * edges.shape[1])\n",
    "    return edge_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 240\n",
    "\n",
    "# Saturation Level Threshold\n",
    "saturation_threshold = 8  # Adjust this value as needed\n",
    "\n",
    "# Input folder path\n",
    "input_folder = 'Converted_Images'\n",
    "\n",
    "# Get a list of all image files in the input folder\n",
    "image_files = os.listdir(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image file\n",
    "for file_name in image_files:\n",
    "    # Construct the full path for the input and output images\n",
    "    input_image_path = os.path.join(input_folder, file_name)\n",
    "    output_image_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Load the input image\n",
    "    image = cv2.imread(input_image_path)\n",
    "\n",
    "    # Calculate image metrics\n",
    "    average_intensity = np.mean(image)\n",
    "    entropy = calculate_entropy(image)\n",
    "    edge_density = calculate_edge_density(image)\n",
    "    saturation = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)[:, :, 1].mean()\n",
    "\n",
    "    # Check if preprocessing is needed based on the criteria\n",
    "    if (average_intensity < threshold or entropy < 4) and (edge_density > 0.03 or saturation < saturation_threshold):\n",
    "        # Apply Color Correction\n",
    "        color_corrected_image = color_correction(image)\n",
    "        # Apply Brightness Adjustment\n",
    "        adjusted_image = adjust_brightness(color_corrected_image, 230)\n",
    "\n",
    "        # Save the processed image\n",
    "        cv2.imwrite(output_image_path, adjusted_image)\n",
    "        print(\"Processed Image saved at:\", output_image_path)\n",
    "    else:\n",
    "        # Save the original image without preprocessing\n",
    "        cv2.imwrite(output_image_path, image)\n",
    "        print(\"Original Image saved at:\", output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindee import Client, documents\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindee_client = Client(api_key=\"\") #API key\n",
    "input_folder = \"Processed_Images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all image files in the input folder\n",
    "image_files = os.listdir(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each image file\n",
    "for file_name in image_files:\n",
    "    # Construct the full path for the input image\n",
    "    input_image_path = os.path.join(input_folder, file_name)\n",
    "    \n",
    "    print(\"Processing image:\", file_name)\n",
    "    \n",
    "    # Create a document from the image\n",
    "    input_doc = mindee_client.doc_from_path(input_image_path)\n",
    "    \n",
    "    # Parse the document using the TypeInvoiceV4 template\n",
    "    api_response = input_doc.parse(documents.TypeInvoiceV4)\n",
    "    \n",
    "    # Check if relevant data is found\n",
    "    if api_response.document is None:\n",
    "        print(\"No relevant data found\")\n",
    "    else:\n",
    "        # Retrieve the extracted information\n",
    "        invoice_number = api_response.document.invoice_number\n",
    "        total_amount = api_response.document.total_amount\n",
    "        invoice_date = api_response.document.invoice_date\n",
    "        reference_numbers = api_response.document.reference_numbers\n",
    "        # reference_numbers = api_response.document.reference_numbers\n",
    "\n",
    "        \n",
    "        print(\"Invoice Number:\", invoice_number)\n",
    "        print(\"Total Amount:\", total_amount)\n",
    "        print(\"Invoice Date:\", invoice_date)\n",
    "        \n",
    "        for reference_number in reference_numbers:\n",
    "            if reference_number.value.startswith(\"4\"):\n",
    "                print(\"Purchase Order Number:\", reference_number.value)\n",
    "            else:\n",
    "                print(\"Reference Numbers:\", reference_number.value)\n",
    "        # print(api_response.document)\n",
    "    \n",
    "    print(\"---------------------------------------------------\")  # Add a newline between images\n",
    "    print(\"---------------------------------------------------\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
